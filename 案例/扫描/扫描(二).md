# MF_ Scan Effect _ Scan Expansion Ring

这是个材质函数,类似actor中创建函数,方便于集合运算
![[Pasted image 20240219151123.png]]
首先获得圆形,然后通过厚度来控制边缘的锐度,锐度越高则结果中圆越小
外圈比外圈多减去一次厚度,所以外圈比内圈大
==最后结合在一起形成了环状==

---
# MF_ Scan Effect _ Radial Distortion

==这个函数用于将画面失真,并产生像素化效果==
首先使用MF_ScanEffect_ScanExpansionRing得到
![[Pasted image 20240219155622.png]]
![[Pasted image 20240219155759.png]]
内圈偏移用于控制里面黑色圆的周围灰色.数值越大灰色越少

开始对厚度和半径的处理是为了圆可以在四边形四个角结束
![[Pasted image 20240219161606.png]]
然后将画面栅格化
1. **UV 缩放和取整**：
    
    - 首先，我们将纹理坐标（UV）乘以一个数值，这会放大或缩小 UV 空间。
    - 然后，我们使用 **Round** 节点将结果四舍五入，将小数部分转换为整数。
    - 最后，我们再将结果除以之前乘的那个数，将值回到原始的线性区间。
2. **为什么这样做可以获得栅格效果**：
    
    - 这个过程实际上是将连续的 UV 坐标映射到离散的网格坐标。
    - 通过缩放、取整和再缩放，我们将 UV 空间分割成一系列网格单元。
    - 每个网格单元对应一个纹理像素，从而形成了栅格效果。
3. **控制栅格大小**：
    
    - 通过调整乘法和除法的数值，我们可以控制栅格的大小。
    - 较大的数值会导致更大的栅格，而较小的数值会产生更小的栅格。


	#材质节点 *ConstantBiasScale*节点:通常出现在sin函数后,用于调整函数的上下位置和振幅
	
	这个节点有两个参数：
	
	1. **Bias（偏移）**：调整曲线在 Y 轴的上下位置。
	2. **Scale（缩放）**：调节振幅，也就是曲线的最大值和最小值。
	
	具体来说，**ConstantBiasScale** 节点的计算公式如下：
	
	$$
	y = (input + bias) scale
	$$
	
	其中，**input** 是输入值（通常是一个纹理或其他材质属性），**bias** 是偏移量，而 **scale** 则是缩放因子。这个节点的作用是将输入值从 [0, 1] 的范围（通常是 RGBA8 纹理值）转换为世界坐标空间中的偏移量，范围在 -128 到 128 之间

# 剔除角色
首先在项目设置里将"后期处理/自定义深度-模板通道"设置为启用模板![[Pasted image 20240226135512.png]]
然后在需要描边或者需要忽略的物体找到![[Pasted image 20240226135604.png]]
然后通过表格来给予材质id控制描边![[Pasted image 20240226135647.png]]
[【UE4】虚幻4使用后期处理制作的发光轮廓线效果_哔哩哔哩_bilibili](https://www.bilibili.com/video/av25758949/?vd_source=8b41b84c9cc89fc6c3cbe28722863704)

# 体素化
#名词解释  在图形渲染中，体素化是将三维世界中的物体或场景转换为规则的三维网格坐标系统（称为“体素网格”）的过程。这通常用于优化体积渲染、光线追踪等技术。

将世界位置进行体素化，四舍五入为网格单元，并转换为具有剪辑空间变换和视角投影的UV。这样可以得到用于映射后处理缓冲区的体素化UV。然而，由于深度缓冲区重建的原因，世界位置存在抖动现象，导致网格单元舍入不精确，进而使得体素化效果不稳定。因此，在扫描扩展分辨率变得更准确之前，我只在该过程中使用它，并在完全扩展后恢复使用texcoord[0]（即bFadedIn从0切换到1）。![[Pasted image 20240227185002.png]]

其中使用了自定义表达式,  编写自定义的HLSL着色器代码，操作任意数量的输入并输出操作结果。
```
// Transform world position into clip position
// In UE4, this was:
//  float4 PixelCoordinate = mul(float4(WorldPosition, 1.0f), view.WorldToClip);
const float4 PixelCoordinate = mul(float4(WorldPosition, 1.0f), LWCToFloat(ResolvedView.WorldToClip));

// perspective deprojection
const float2 UV = ((PixelCoordinate.xy / PixelCoordinate.w) + 1.0f) * 0.5f;

// flip y channel
return float2(UV.x, 1.0f - UV.y);

```
这段代码实际上是在图形渲染中进行坐标变换的一部分。让我们逐步分解它：

1. **世界坐标转裁剪坐标**：
    
    - 首先，我们有一个世界坐标（`WorldPosition`）。
    - 然后，我们将其与视图矩阵（`view.WorldToClip`）相乘，以获得裁剪坐标（`PixelCoordinate`）。
    - 这个裁剪坐标是一个四维向量，其中x、y和z分量表示屏幕上的位置，w分量是透视除法所需的值。
2. **透视反投影**：
    
    - 接下来，我们将裁剪坐标的x和y分量除以w分量，加1并除以2，以将其映射到[0, 1]范围内。
    - 这是一种透视反投影的过程，将裁剪坐标映射到屏幕空间。
3. **翻转y通道**：
    
    - 最后，我们将UV的y分量翻转，以适应纹理坐标的约定。在纹理坐标中，原点通常位于左上角。

总之，这段代码的目的是将世界坐标转换为纹理坐标，以便在图形渲染中进行后处理。

